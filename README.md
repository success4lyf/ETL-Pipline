# ETL-Pipline
> Building a fully scalable ETL (Extract, Transform, Load) pipeline to handle large volumes of transaction data for a café business.

## Table of Content
1. Project Overview
2. Project Vision
3. [Sprint 1 - ETL-Pipline](https://github.com/success4lyf/ETL-Pipline)
4. [Sprint 2 - AWS-Data-Warehouse](https://github.com/success4lyf/AWS-Data-Warehouse)

## Project Overview
In this project, a fully scalable ETL (Extract, Transform, Load) pipeline is built to handle large volumes of transaction data for a café business that has many branches. This pipeline will collect all the transaction data generated by each individual café branch and place it in a single location. By being able to easily query the company's data as a whole, the client will drastically increase their ability to identify company-wide trends and insights.

Using agile methodology, the project was built slowly and adding more complexity to it as time progresses. The project consist of five sprints, where each sprint is a week in length with different task from the product owner in the product backlog.

## Project Vision
Below is a vision of what both parties would like to produce as the end result.
- Each night a CSV for each branch will be uploaded to the cloud. 
- The system we have developed will read each file and perform ETL steps.
- Data will be stored in a data warehouse
- Data analytics software will be used to create Business Intelligence analytics for the client
- Application monitoring software will be used to produce operational metrics, such as system errors, up-time and more.

## Sprint 1 - ETL-Pipline
